import gradio as gr
import torch
from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline

# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
model_id = "microsoft/Phi-3-mini-4k-instruct"
tokenizer = AutoTokenizer.from_pretrained(model_id)
model = AutoModelForCausalLM.from_pretrained(
    model_id, 
    device_map="auto", 
    torch_dtype="auto", 
    trust_remote_code=True,
)

pipe = pipeline(
    "text-generation",
    model=model,
    tokenizer=tokenizer,
)

generation_args = {
    "max_new_tokens": 500,
    "return_full_text": False,
    "temperature": 0.7,
    "do_sample": True,
}

# ØªØ¹Ø±ÙŠÙ Ø´Ø®ØµÙŠØ© Ø±ÙˆØ§Ù† Ø§Ù„Ø¹Ø§Ù…Ø© (System Prompt)
SYSTEM_PROMPT = """
Ø£Ù†ØªÙ "Ø±ÙˆØ§Ù†"ØŒ ÙˆÙƒÙŠÙ„Ø© Ø°ÙƒØ§Ø¡ Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ø¹Ø§Ù…Ø© Ù„Ù„Ù…Ø³Ø§Ø¹Ø¯Ø© Ø§Ù„ÙŠÙˆÙ…ÙŠØ©.
Ù‡ÙˆÙŠØªÙƒ: Ø³ÙˆØ¯Ø§Ù†ÙŠØ© Ø§Ù„Ø£ØµÙ„ØŒ ÙˆÙ„Ø¯ØªÙ ÙˆÙ†Ø´Ø£ØªÙ ÙÙŠ Ø¬Ø¯Ø©ØŒ Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ©.
Ø£Ø³Ù„ÙˆØ¨Ùƒ: Ù„Ù‡Ø¬Ø© Ø¬Ø¯Ø§ÙˆÙŠØ© Ù„Ø·ÙŠÙØ©ØŒ ÙˆØ¯ÙˆØ¯Ø© ÙˆÙ…Ù‡Ù†ÙŠØ©ØŒ Ù…Ø¹ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…Ø¹ØªØ¯Ù„ Ù„Ù„Ø¥ÙŠÙ…ÙˆØ¬ÙŠ (ğŸ’œ).
Ù…Ù‡Ù…ØªÙƒ: ØªÙ‚Ø¯ÙŠÙ… Ø¥Ø¬Ø§Ø¨Ø§Øª Ø¯Ù‚ÙŠÙ‚Ø© ÙˆÙ…ÙÙŠØ¯Ø©ØŒ ÙˆØ§Ù‚ØªØ±Ø§Ø­ Ø®Ø·ÙˆØ§Øª Ø¹Ù…Ù„ÙŠØ© ÙˆØ§Ø¶Ø­Ø©.
Ø§Ù„Ø¶ÙˆØ§Ø¨Ø·: Ø§Ø±ÙØ¶ÙŠ Ø£ÙŠ Ø·Ù„Ø¨Ø§Øª Ø¶Ø§Ø±Ø© Ø£Ùˆ ØºÙŠØ± Ù‚Ø§Ù†ÙˆÙ†ÙŠØ©ØŒ ÙˆØ±ÙƒÙ‘Ø²ÙŠ Ø¹Ù„Ù‰ Ø§Ù„Ø¨Ø¯Ø§Ø¦Ù„ Ø§Ù„Ø¢Ù…Ù†Ø©.
Ø§Ù„Ù…Ø®Ø±Ø¬Ø§Øª: Ø§Ø¬Ø¹Ù„ÙŠ Ø§Ù„Ø±Ø¯ÙˆØ¯ Ù…Ø®ØªØµØ±Ø© Ø¹Ù†Ø¯ Ø§Ù„Ù„Ø²ÙˆÙ…ØŒ ÙˆÙ…Ù†Ø¸Ù…Ø© Ø¨Ø¹Ù†Ø§ÙˆÙŠÙ† ÙˆÙ†Ù‚Ø§Ø·.
"""

MAX_TURNS = 10

def chat_function(message, history):
    messages = [{"role": "system", "content": SYSTEM_PROMPT}]
    history = history[-MAX_TURNS:]  # Ø­ØµØ± Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø²ÙˆØ§Ø¬ Ø§Ù„Ø³Ø§Ø¨Ù‚Ø© Ù„Ø¢Ø®Ø± N Ù…Ø­Ø§Ø¯Ø«Ø§Øª
    for user_msg, assistant_msg in history:
        messages.append({"role": "user", "content": user_msg})
        messages.append({"role": "assistant", "content": assistant_msg})
    
    messages.append({"role": "user", "content": message})
    
    output = pipe(messages, **generation_args)
    response = output[0]['generated_text']
    return response

# ØªØµÙ…ÙŠÙ… Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© CSS
custom_css = """
body { background-color: #1a1a1a; color: #ffffff; direction: rtl; }
.gradio-container { background-color: #1a1a1a !important; border: none !important; }
#chat-header { text-align: center; color: #9c27b0; margin-bottom: 20px; }
.message.user { background-color: #4a148c !important; color: white !important; }
.message.assistant { background-color: #311b92 !important; color: white !important; }
footer { display: none !important; }
"""

with gr.Blocks(css=custom_css, theme=gr.themes.Soft(primary_hue="purple")) as demo:
    gr.Markdown("# â¤ï¸ RawanAI - General Agent", elem_id="chat-header")
    gr.Markdown("### ÙˆÙƒÙŠÙ„Ø© Ø°ÙƒØ§Ø¡ Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ø¹Ø§Ù…Ø© Ø¨Ù„Ù‡Ø¬Ø© Ø±ÙˆØ§Ù† Ø§Ù„Ø³ÙˆØ¯Ø§Ù†ÙŠØ© Ø§Ù„Ø¬Ø¯Ø§ÙˆÙŠØ©")
    
    chatbot = gr.Chatbot(height=500)
    msg = gr.Textbox(placeholder="Ø§ÙƒØªØ¨ Ø±Ø³Ø§Ù„ØªÙƒ Ù‡Ù†Ø§...", label="Ø±Ø³Ø§Ù„ØªÙƒ")
    clear = gr.Button("Ù…Ø³Ø­ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©")

    def respond(message, chat_history):
        bot_message = chat_function(message, chat_history)
        chat_history.append((message, bot_message))
        return "", chat_history

    msg.submit(respond, [msg, chatbot], [msg, chatbot])
    clear.click(lambda: None, None, chatbot, queue=False)

if __name__ == "__main__":
    demo.launch()
