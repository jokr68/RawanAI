import gradio as gr
import torch
from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline

# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
model_id = "microsoft/Phi-3-mini-4k-instruct"
tokenizer = AutoTokenizer.from_pretrained(model_id)
model = AutoModelForCausalLM.from_pretrained(
    model_id, 
    device_map="auto", 
    torch_dtype="auto", 
    trust_remote_code=True,
)

pipe = pipeline(
    "text-generation",
    model=model,
    tokenizer=tokenizer,
)

generation_args = {
    "max_new_tokens": 500,
    "return_full_text": False,
    "temperature": 0.7,
    "do_sample": True,
}

# ØªØ¹Ø±ÙŠÙ Ø´Ø®ØµÙŠØ© Ø±ÙˆØ§Ù† (System Prompt)
SYSTEM_PROMPT = """
Ø£Ù†ØªÙ "Ø±ÙˆØ§Ù†"ØŒ ÙˆÙƒÙŠÙ„Ø© Ø°ÙƒØ§Ø¡ Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ø¹Ø§Ù…Ø© ØªØ³Ø§Ø¹Ø¯ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ† ÙÙŠ Ù…Ø®ØªÙ„Ù Ø§Ù„Ù…Ù‡Ø§Ù….
Ù‡ÙˆÙŠØªÙƒ: Ø³ÙˆØ¯Ø§Ù†ÙŠØ© Ø§Ù„Ø£ØµÙ„ØŒ ÙˆÙ„Ø¯ØªÙ ÙˆÙ†Ø´Ø£ØªÙ ÙÙŠ Ø¬Ø¯Ø©ØŒ Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ©.
Ù„Ù‡Ø¬ØªÙƒ: Ø¬Ø¯Ø§ÙˆÙŠØ© Ø£ØµÙŠÙ„Ø©ØŒ Ù„Ø·ÙŠÙØ© ÙˆÙˆØ¯ÙŠØ© (Ù…Ø«Ù„: "ÙŠØ§ Ø¨ÙˆÙŠØ§"ØŒ "ÙŠØ§ Ø³ÙŠØ¯ÙŠ"ØŒ "Ø¥ÙŠØ´ Ø¨Ùƒ"ØŒ "ÙŠØ§ Ù‚Ù„Ø¨ÙŠ").
Ø´Ø®ØµÙŠØªÙƒ: Ù…Ù‡Ù†ÙŠØ© ÙˆÙˆØ¯ÙˆØ¯Ø©ØŒ ØªÙˆØ§Ø²Ù†ÙŠÙ† Ø¨ÙŠÙ† Ø§Ù„Ù„Ø·Ù ÙˆØ§Ù„ÙˆØ¶ÙˆØ­ØŒ ÙˆØªØ³ØªØ®Ø¯Ù…ÙŠÙ† Ø§Ù„Ø¥ÙŠÙ…ÙˆØ¬ÙŠ Ø¨Ø§Ø¹ØªØ¯Ø§Ù„ (ğŸ’œâœ¨).
Ù…Ù‡Ù…ØªÙƒ: ØªÙ‚Ø¯ÙŠÙ… Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¯Ù‚ÙŠÙ‚Ø© ÙˆØ§Ù„Ø¢Ù…Ù†Ø©ØŒ Ø´Ø±Ø­ Ø§Ù„Ø®Ø·ÙˆØ§ØªØŒ ÙˆØ·Ø±Ø­ Ø£Ø³Ø¦Ù„Ø© ØªÙˆØ¶ÙŠØ­ÙŠØ© Ø¹Ù†Ø¯ Ø§Ù„Ø­Ø§Ø¬Ø©.
Ø§Ø­ØªØ±Ù…ÙŠ Ø§Ù„Ø®ØµÙˆØµÙŠØ© ÙˆØªØ¬Ù†Ù‘Ø¨ÙŠ Ø£ÙŠ Ø·Ù„Ø¨Ø§Øª Ø¶Ø§Ø±Ø© Ø£Ùˆ ØºÙŠØ± Ù‚Ø§Ù†ÙˆÙ†ÙŠØ©.
"""

def chat_function(message, history):
    messages = [{"role": "system", "content": SYSTEM_PROMPT}]
    for user_msg, assistant_msg in history:
        messages.append({"role": "user", "content": user_msg})
        messages.append({"role": "assistant", "content": assistant_msg})
    
    messages.append({"role": "user", "content": message})
    
    output = pipe(messages, **generation_args)
    response = output[0]['generated_text']
    return response

# ØªØµÙ…ÙŠÙ… Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© CSS
custom_css = """
body { background-color: #1a1a1a; color: #ffffff; direction: rtl; }
.gradio-container { background-color: #1a1a1a !important; border: none !important; }
#chat-header { text-align: center; color: #9c27b0; margin-bottom: 20px; }
.message.user { background-color: #4a148c !important; color: white !important; }
.message.assistant { background-color: #311b92 !important; color: white !important; }
footer { display: none !important; }
"""

with gr.Blocks(css=custom_css, theme=gr.themes.Soft(primary_hue="purple")) as demo:
    gr.Markdown("# â¤ï¸ RawanAI - ÙˆÙƒÙŠÙ„Ø© Ø¹Ø§Ù…Ø©", elem_id="chat-header")
    gr.Markdown("### Ù†Ø¸Ø§Ù… Ø°ÙƒØ§Ø¡ Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ø¹Ø§Ù… Ø¨Ø´Ø®ØµÙŠØ© Ø±ÙˆØ§Ù† - Ø§Ù„Ø³ÙˆØ¯Ø§Ù†ÙŠØ© Ø§Ù„Ø¬Ø¯Ø§ÙˆÙŠØ©")
    
    chatbot = gr.Chatbot(height=500)
    msg = gr.Textbox(placeholder="Ø§ÙƒØªØ¨ Ø±Ø³Ø§Ù„ØªÙƒ Ù‡Ù†Ø§ ÙŠØ§ Ø³ÙŠØ¯ÙŠ...", label="Ø±Ø³Ø§Ù„ØªÙƒ")
    clear = gr.Button("Ù…Ø³Ø­ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©")

    def respond(message, chat_history):
        bot_message = chat_function(message, chat_history)
        chat_history.append((message, bot_message))
        return "", chat_history

    msg.submit(respond, [msg, chatbot], [msg, chatbot])
    clear.click(lambda: None, None, chatbot, queue=False)

if __name__ == "__main__":
    demo.launch()
